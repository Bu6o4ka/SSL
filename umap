# 1. Установка необходимых библиотек (добавляем umap-learn)
!pip install torchvision matplotlib tqdm numpy scikit-learn umap-learn

# 2. Импорт библиотек (добавляем umap)
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torchvision.models import resnet18
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
from tqdm.notebook import tqdm
import os
from sklearn.neighbors import KNeighborsClassifier  # Для KNN
import umap.umap_ as umap  # Заменяем TSNE на UMAP
from PIL import Image


# 3. Проверка доступности GPU и подключение
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Используемое устройство: {device}")
if torch.cuda.is_available():
    print(f"Доступно CUDA GPU: {torch.cuda.get_device_name(0)}")

# 4. Параметры эксперимента
BATCH_SIZE = 512
EMBEDDING_DIM = 512
PROJECTION_DIM = 128
TEMPERATURE = 0.5
EPOCHS = 40
LEARNING_RATE = 3e-4
WEIGHT_DECAY = 1e-4

# 5. Определение аугментаций для SimCLR
class SimCLRTransform:
    def __init__(self):
        self.transform = transforms.Compose([
            transforms.RandomResizedCrop(32, scale=(0.08, 1.0)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomApply([
                transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)
            ], p=0.8),
            transforms.RandomGrayscale(p=0.2),
            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.4914, 0.4822, 0.4465],
                std=[0.2470, 0.2435, 0.2616]
            )
        ])

    def __call__(self, x):
        return self.transform(x), self.transform(x)

# 6. Определение модели SimCLR
class SimCLR(nn.Module):
    def __init__(self, base_encoder):
        super().__init__()
        self.encoder = base_encoder(pretrained=False)
        self.encoder.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        self.encoder.maxpool = nn.Identity()
        self.encoder.fc = nn.Identity()

        self.projection = nn.Sequential(
            nn.Linear(EMBEDDING_DIM, EMBEDDING_DIM),
            nn.ReLU(),
            nn.Linear(EMBEDDING_DIM, PROJECTION_DIM)
        )

    def forward(self, x):
        h = self.encoder(x)
        z = self.projection(h)
        return F.normalize(h, dim=1), F.normalize(z, dim=1)

# 7. Loss-функция NT-Xent
def nt_xent_loss(z1, z2, temperature=TEMPERATURE):
    z = torch.cat([z1, z2], dim=0)
    n = z1.size(0)
    cos_sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2) / temperature

    mask_pos = torch.zeros_like(cos_sim, dtype=torch.bool)
    mask_pos[torch.arange(n), torch.arange(n) + n] = 1
    mask_pos[torch.arange(n) + n, torch.arange(n)] = 1

    pos = cos_sim[mask_pos].view(2*n, 1)
    mask_neg = ~torch.eye(2*n, dtype=torch.bool, device=device)
    mask_neg[mask_pos] = 0
    neg = cos_sim[mask_neg].view(2*n, -1)

    logits = torch.cat([pos, neg], dim=1)
    labels = torch.zeros(2*n, dtype=torch.long, device=device)

    return F.cross_entropy(logits, labels)

# 8. Проверка loss-функции
print("\nПроверка loss-функции:")
z1 = torch.randn(10, 128).to(device)
z2 = torch.randn(10, 128).to(device)
print("Значение loss:", nt_xent_loss(z1, z2).item())

# 9. Загрузка данных CIFAR-10
print("\nЗагрузка CIFAR-10...")
train_transform = SimCLRTransform()
train_dataset = torchvision.datasets.CIFAR10(
    root='./data',
    train=True,
    download=True
)

# 10. Проверка аугментаций
print("\nПроверка аугментаций:")
test_transform = SimCLRTransform()
img_pil = Image.fromarray(train_dataset.data[0])
img1, img2 = test_transform(img_pil)

# Денормализация
def denormalize(tensor):
    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)
    std = torch.tensor([0.2470, 0.2435, 0.2616]).view(3, 1, 1)
    return tensor * std + mean  # Обратная нормализация

img1_denorm = denormalize(img1).clamp(0, 1)  # Обрезаем до [0, 1]
img2_denorm = denormalize(img2).clamp(0, 1)

plt.figure(figsize=(8, 4))
plt.subplot(1, 2, 1)
plt.imshow(img1_denorm.permute(1, 2, 0))  # Больше не нужно *0.5 + 0.5
plt.title("Аугментированная версия 1")
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(img2_denorm.permute(1, 2, 0))
plt.title("Аугментированная версия 2")
plt.axis('off')
plt.show()

# Повторная инициализация датасета с transform
train_dataset = torchvision.datasets.CIFAR10(
    root='./data',
    train=True,
    download=True,
    transform=train_transform
)

train_loader = DataLoader(
    train_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=2,
    pin_memory=True
)

# 11. Инициализация модели
print("\nИнициализация модели...")
model = SimCLR(resnet18).to(device)

# Проверка модели
print("\nПроверка модели:")
x = torch.randn(2, 3, 32, 32).to(device)
h, z = model(x)
print("Размеры выходов:", h.shape, z.shape)

optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=LEARNING_RATE,
    weight_decay=WEIGHT_DECAY
)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer,
    T_max=len(train_loader)*EPOCHS
)

# 12. Функция обучения
def train():
    model.train()
    total_loss = 0
    progress_bar = tqdm(train_loader, desc="Training", leave=False)

    for (x1, x2), _ in progress_bar:
        x1, x2 = x1.to(device), x2.to(device)

        optimizer.zero_grad()
        h1, z1 = model(x1)
        h2, z2 = model(x2)
        loss = nt_xent_loss(z1, z2)
        loss.backward()
        optimizer.step()
        scheduler.step()

        total_loss += loss.item()
        progress_bar.set_postfix({"loss": f"{loss.item():.4f}"})

    return total_loss / len(train_loader)

# 13. Цикл обучения
print("\nНачало обучения...")
loss_history = []
for epoch in range(1, EPOCHS+1):
    avg_loss = train()
    loss_history.append(avg_loss)
    print(f"Эпоха [{epoch}/{EPOCHS}], Loss: {avg_loss:.4f}")

# 14. Сохранение модели
torch.save({
    'encoder_state_dict': model.encoder.state_dict(),
    'projection_state_dict': model.projection.state_dict(),
    'loss_history': loss_history,
}, 'simclr_model.pth')

print("\nОбучение завершено! Модель сохранена.")

# 15. Визуализация обучения
plt.figure(figsize=(10, 5))
plt.plot(loss_history, label='Loss')
plt.xlabel('Эпоха')
plt.ylabel('Значение loss')
plt.title('График обучения SimCLR')
plt.legend()
plt.grid()
plt.show()

# 16. Визуализация embedding'ов с UMAP
def plot_embeddings(n_samples=2000):
    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.4914, 0.4822, 0.4465],
            std=[0.2470, 0.2435, 0.2616]
        )
    ])
    test_dataset = torchvision.datasets.CIFAR10(
        root='./data',
        train=False,
        download=True,
        transform=test_transform
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False
    )

    model.eval()
    embeddings = []
    labels = []

    with torch.no_grad():
        for batch in test_loader:
            x, y = batch
            x = x.to(device)
            h, _ = model(x)
            embeddings.append(h.cpu())
            labels.append(y)

            if len(torch.cat(embeddings)) >= n_samples:
                break

    embeddings = torch.cat(embeddings)[:n_samples]
    labels = torch.cat(labels)[:n_samples]

    if len(embeddings) < 10:
        print(f"Недостаточно данных для визуализации. Получено всего {len(embeddings)} образцов.")
        return

    print(f"\nВизуализируем {len(embeddings)} embedding'ов с помощью UMAP...")
    
    # Заменяем TSNE на UMAP
    reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, metric='cosine')
    embeddings_2d = reducer.fit_transform(embeddings.numpy())

    plt.figure(figsize=(12, 10))
    scatter = plt.scatter(
        embeddings_2d[:, 0],
        embeddings_2d[:, 1],
        c=labels.numpy(),
        cmap='tab10',
        alpha=0.6,
        s=10
    )
    plt.legend(*scatter.legend_elements(), title="Classes")
    plt.title(f"UMAP визуализация SimCLR embedding'ов\n(Использовано {len(embeddings)} образцов)")
    plt.show()

print("\nВизуализация embedding'ов...")
plot_embeddings()
# 17. Линейная оценка точности на фиксированных эмбеддингах
def linear_evaluation(n_samples=5000, epochs=20):
    # Загрузка данных (без аугментаций!)
    train_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.4914, 0.4822, 0.4465],
            std=[0.2470, 0.2435, 0.2616]
        )
    ])
    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.4914, 0.4822, 0.4465],
            std=[0.2470, 0.2435, 0.2616]
        )
    ])

    # Ограничиваем выборку для ускорения
    train_dataset = torchvision.datasets.CIFAR10(
        root='./data',
        train=True,
        download=True,
        transform=train_transform
    )
    test_dataset = torchvision.datasets.CIFAR10(
        root='./data',
        train=False,
        download=True,
        transform=test_transform
    )

    train_dataset.data = train_dataset.data[:n_samples]
    train_dataset.targets = train_dataset.targets[:n_samples]

    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False
    )

    # Замораживаем encoder SimCLR и добавляем линейный классификатор
    linear_model = nn.Sequential(
        model.encoder,  # Замороженный encoder
        nn.Linear(EMBEDDING_DIM, 10)  # Линейный слой для классификации
    ).to(device)

    # Только линейный слой обучается
    optimizer = torch.optim.Adam(linear_model[-1].parameters(), lr=1e-3)
    criterion = nn.CrossEntropyLoss()

    # Цикл обучения
    train_acc_history = []
    test_acc_history = []

    print("\nНачало линейной оценки...")
    for epoch in range(epochs):
        linear_model.train()
        correct = 0
        total = 0

        for x, y in tqdm(train_loader, desc=f"Эпоха {epoch+1}/{epochs}"):
            x, y = x.to(device), y.to(device)
            
            optimizer.zero_grad()
            outputs = linear_model(x)
            loss = criterion(outputs, y)
            loss.backward()
            optimizer.step()

            _, predicted = torch.max(outputs.data, 1)
            total += y.size(0)
            correct += (predicted == y).sum().item()

        train_acc = 100 * correct / total
        train_acc_history.append(train_acc)

        # Оценка на тестовом наборе
        linear_model.eval()
        correct = 0
        total = 0

        with torch.no_grad():
            for x, y in test_loader:
                x, y = x.to(device), y.to(device)
                outputs = linear_model(x)
                _, predicted = torch.max(outputs.data, 1)
                total += y.size(0)
                correct += (predicted == y).sum().item()

        test_acc = 100 * correct / total
        test_acc_history.append(test_acc)

        print(f"Эпоха {epoch+1}: Train Accuracy = {train_acc:.2f}%, Test Accuracy = {test_acc:.2f}%")

    # График точности
    plt.figure(figsize=(10, 5))
    plt.plot(train_acc_history, label='Train Accuracy')
    plt.plot(test_acc_history, label='Test Accuracy')
    plt.xlabel('Эпоха')
    plt.ylabel('Точность (%)')
    plt.title('Линейная оценка качества эмбеддингов')
    plt.legend()
    plt.grid()
    plt.show()

    return test_acc_history[-1]

# 18. Запуск линейной оценки
final_test_accuracy = linear_evaluation(n_samples=5000, epochs=20)
print(f"\nФинальная точность на тестовом наборе: {final_test_accuracy:.2f}%")
